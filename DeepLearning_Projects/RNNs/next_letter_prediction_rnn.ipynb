{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNT983r1QKA2XLCbmVLxp4r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naikamal/HandsOnPytorch/blob/main/DeepLearning_Projects/RNNs/next_letter_prediction_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Import Libraries"
      ],
      "metadata": {
        "id": "3KaI5TXZkGpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random"
      ],
      "metadata": {
        "id": "fwh2pQGb3QaY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Build Character Vocabulary\n"
      ],
      "metadata": {
        "id": "PXp6o1q6kLCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names=['naikamalshah','raheemshah','taimurkhan','dayankhan']\n",
        "\n",
        "all_chars=sorted(set(\"\".join(names)))\n",
        "char_to_idx={char:i for i,char in enumerate(all_chars)} # maps 'a' → 0, 'h' → 1, etc.\n",
        "idx_to_char={i:char for char,i in char_to_idx.items()}\n",
        "vocab_size=len(all_chars)\n",
        "print(f\"All unique characters: {all_chars}\")\n",
        "# print(f\"char to idx: {char_to_idx}\")\n",
        "# print(f\"idx to char: {idx_to_char}\")\n",
        "print(f\"Vocablary size: {vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxjNGL--3kcr",
        "outputId": "bde36f25-15c3-40fd-c4b0-8abfb2ec12a5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All unique characters: ['a', 'd', 'e', 'h', 'i', 'k', 'l', 'm', 'n', 'r', 's', 't', 'u', 'y']\n",
            "Vocablary size: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Prepare Dataset"
      ],
      "metadata": {
        "id": "wq1wWVaprQjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pairs(name):\n",
        "  inputs,targets=[],[]\n",
        "  for i in range(len(name)-1):\n",
        "    inputs.append(char_to_idx[name[i]])\n",
        "    targets.append(char_to_idx[name[i+1]])\n",
        "\n",
        "  return inputs,targets\n",
        ""
      ],
      "metadata": {
        "id": "yZHH-qdU6OI5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Define the RNN Model"
      ],
      "metadata": {
        "id": "V5xw89HExDKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CharRNN(nn.Module):\n",
        "  def __init__(self,vocab_size,hidden_size):\n",
        "    super().__init__()\n",
        "    self.embed=nn.Embedding(vocab_size,hidden_size)\n",
        "    self.rnn=nn.RNN(hidden_size,hidden_size,batch_first=True)\n",
        "    self.fc=nn.Linear(hidden_size,vocab_size)\n",
        "\n",
        "\n",
        "#  Forward Function\n",
        "  def forward(self,x,hidden):\n",
        "    x=self.embed(x)\n",
        "    out,hidden=self.rnn(x,hidden)\n",
        "    out=self.fc(out)\n",
        "    return out,hidden\n",
        "\n",
        "# Flow of data:\n",
        "# [char_indices] → embed → rnn → linear → predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "IIbL_K0o7Ujd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Model Setup"
      ],
      "metadata": {
        "id": "NypVly9cBU6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size=32\n",
        "model=CharRNN(vocab_size,hidden_size)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.01)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n_zOvJWfBdBk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Train the RNN"
      ],
      "metadata": {
        "id": "C1I5FxRpGAy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(200):\n",
        "  name=random.choice(names)\n",
        "  inputs_idx,targets_idx=make_pairs(name)\n",
        "\n",
        "  input_tensor=torch.tensor([inputs_idx],dtype=torch.long)\n",
        "  target_tensor=torch.tensor([targets_idx],dtype=torch.long)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  hidden=torch.zeros(1,1,hidden_size) #num_layers=1, batch=1\n",
        "\n",
        "  output,new_hidden=model(input_tensor,hidden)\n",
        "  loss=criterion(output.squeeze(0),target_tensor.squeeze(0))\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%20==0:\n",
        "    print(f\"Epoch:{epoch}, Loss:{loss.item():.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN5ZMsa53HED",
        "outputId": "1bf92f4c-c3a9-4901-9d81-eb3093237084"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0, Loss:2.6882\n",
            "Epoch:20, Loss:0.7618\n",
            "Epoch:40, Loss:0.2478\n",
            "Epoch:60, Loss:0.1036\n",
            "Epoch:80, Loss:0.0724\n",
            "Epoch:100, Loss:0.0228\n",
            "Epoch:120, Loss:0.0187\n",
            "Epoch:140, Loss:0.0167\n",
            "Epoch:160, Loss:0.0107\n",
            "Epoch:180, Loss:0.0114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Predicting Next Character"
      ],
      "metadata": {
        "id": "V0LG-4G_UKnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next(name_seed, model,hidden_size):\n",
        "  for ch in name_seed:\n",
        "    if ch not in char_to_idx:\n",
        "      raise ValueError(f\"character {ch} is not in vocablary!\")\n",
        "\n",
        "  input_idx=[char_to_idx[ch] for ch in name_seed]\n",
        "  input_tensor=torch.tensor([input_idx],dtype=torch.long)\n",
        "  hidden=torch.zeros(1,1,hidden_size)\n",
        "\n",
        "  output,new_hidden=model(input_tensor,hidden)\n",
        "  last_logits = output[0, -1]  # output of last time step\n",
        "  pred_idx=torch.argmax(last_logits).item()\n",
        "\n",
        "  return idx_to_char[pred_idx]\n",
        "\n",
        "print(predict_next(\"kha\",model,hidden_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmmaJ7tlMbg_",
        "outputId": "5177a9e7-cf4f-4f07-80f9-ea2d4da43030"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XeJH8C7QaJom"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}